{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src import data_prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "post, thread=data_prepare.load_train_data()\n",
    "post_test, thread_test=data_prepare.load_test_data()\n",
    "label_map=data_prepare.load_label_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=len(thread)\n",
    "train_data_to_clean=[]\n",
    "test_data_to_clean=[]\n",
    "\n",
    "#train_data_to_clean=data_prepare.get_all_text_data_from_posts(post, thread)\n",
    "#test_data_to_clean=data_prepare.get_all_text_data_from_posts(post_test, thread_test)\n",
    "\n",
    "\n",
    "clean_train_data = [data_prepare.clean(s) for s in thread[\"thread_name\"]]\n",
    "clean_test_data = [data_prepare.clean(s) for s in thread[\"thread_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "X_test=clean_test_data\n",
    "X_train=clean_train_data\n",
    "y_train=thread[\"thread_label_id\"]\n",
    "#X_train, X_val, y_train, y_val = train_test_split(clean_train_data, thread[\"thread_label_id\"], test_size=0.2, random_state=213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=3,sublinear_tf=True, norm='l2', encoding='latin-1', ngram_range=(1, 1))\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(X_train).toarray()\n",
    "\n",
    "test_data_features = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_users(post):\n",
    "    return post.groupby(['thread_num','user'],sort=False).size().reset_index('user').rename(index=str, columns={0: \"number_of_posts\"})\n",
    "def avg_and_dev_in_posts_number(df):\n",
    "    return df.groupby(\"thread_num\",sort=False).mean(), df.groupby(\"thread_num\",sort=False).std()\n",
    "def normalize(s):\n",
    "    return (s-s.mean())/s.max()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_quotes_data(post):\n",
    "    quotes_data=post[[\"thread_num\",\"quotes\"]]\n",
    "    a=quotes_data.groupby(\"thread_num\",sort=False).size()\n",
    "    b=quotes_data[quotes_data[\"quotes\"]!=''].groupby(\"thread_num\",sort=False).size()\n",
    "    numb_quotes=pd.Series(index=a.index)\n",
    "    for index,item in a.items():\n",
    "        if index in b.index:\n",
    "            numb_quotes[index]=b.loc[index]\n",
    "        else:\n",
    "            numb_quotes[index]=0\n",
    "    q_perc=(numb_quotes/a).as_matrix()\n",
    "    numb_quotes=normalize(numb_quotes.astype(int).as_matrix())\n",
    "\n",
    "    return numb_quotes, q_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = get_unique_users(post)\n",
    "numb_unique=unique_users.groupby(\"thread_num\",sort=False).nunique()[\"user\"]\n",
    "numb_unique= normalize(numb_unique)\n",
    "\n",
    "avg_numb_of_posts, dev_numb_of_posts = avg_and_dev_in_posts_number(unique_users[[\"number_of_posts\"]])\n",
    "numb_quotes, q_perc=get_quotes_data(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users_test = get_unique_users(post_test)\n",
    "numb_unique_test=unique_users_test.groupby(\"thread_num\",sort=False).nunique()[\"user\"]\n",
    "numb_unique_test=normalize(numb_unique_test)\n",
    "\n",
    "avg_numb_of_posts_test, dev_numb_of_posts_test = avg_and_dev_in_posts_number(unique_users_test[[\"number_of_posts\"]])\n",
    "numb_quotes_test, q_perc_test=get_quotes_data(post_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_train_posts=thread[\"thread_replies\"].as_matrix()\n",
    "number_train_posts=normalize(number_train_posts)\n",
    "\n",
    "number_test_posts=thread_test[\"thread_replies\"].as_matrix()\n",
    "number_test_posts=normalize(number_test_posts)\n",
    "\n",
    "\n",
    "train_data_features=np.concatenate([number_train_posts.reshape(-1,1), numb_unique.as_matrix().reshape(-1,1),\n",
    "                                     numb_quotes.reshape(-1,1),q_perc.reshape(-1,1),\n",
    "                                     avg_numb_of_posts.as_matrix().reshape(-1,1),train_data_features],axis=1)\n",
    "test_data_features=np.concatenate([number_test_posts.reshape(-1,1),numb_unique_test.as_matrix().reshape(-1,1),\n",
    "                             numb_quotes_test.reshape(-1,1),q_perc_test.reshape(-1,1),\n",
    "                             avg_numb_of_posts_test.as_matrix().reshape(-1,1),test_data_features],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(358, 140293) (236, 140293)\n"
     ]
    }
   ],
   "source": [
    "train_X=np.delete(train_data_features,np.s_[101],axis=1)\n",
    "train_X=train_X.reshape(358,10,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes=np.unique(y_train)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_Y_one_hot = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.1, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 20\n",
    "num_classes = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "mafia_model = Sequential()\n",
    "mafia_model.add(Conv2D(16, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(374,374,1)))\n",
    "mafia_model.add(LeakyReLU(alpha=0.1))\n",
    "mafia_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "mafia_model.add(Dropout(0.25))\n",
    "mafia_model.add(Conv2D(32, (3, 3), activation='linear',padding='same'))\n",
    "mafia_model.add(LeakyReLU(alpha=0.1))\n",
    "mafia_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "mafia_model.add(Dropout(0.25))\n",
    "mafia_model.add(Flatten())\n",
    "mafia_model.add(Dense(32, activation='linear'))\n",
    "mafia_model.add(LeakyReLU(alpha=0.1))           \n",
    "mafia_model.add(Dropout(0.3))\n",
    "mafia_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(101, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(101, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(101, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(35))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(101, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "mafia_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 374, 374, 16)      160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 374, 374, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 187, 187, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 187, 187, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 187, 187, 32)      4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 187, 187, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 94, 94, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 94, 94, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 282752)            0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                9048096   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 13)                429       \n",
      "=================================================================\n",
      "Total params: 9,053,325\n",
      "Trainable params: 9,053,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mafia_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 322 samples, validate on 36 samples\n",
      "Epoch 1/20\n",
      "322/322 [==============================] - 89s 277ms/step - loss: 1.5590 - acc: 0.5559 - val_loss: 1.3564 - val_acc: 0.6389\n",
      "Epoch 2/20\n",
      "322/322 [==============================] - 81s 252ms/step - loss: 1.4038 - acc: 0.5745 - val_loss: 1.2290 - val_acc: 0.6111\n",
      "Epoch 3/20\n",
      "322/322 [==============================] - 80s 248ms/step - loss: 1.4109 - acc: 0.5466 - val_loss: 0.9746 - val_acc: 0.6389\n",
      "Epoch 4/20\n",
      "322/322 [==============================] - 80s 248ms/step - loss: 1.4214 - acc: 0.5528 - val_loss: 1.0361 - val_acc: 0.6389\n",
      "Epoch 5/20\n",
      "322/322 [==============================] - 88s 274ms/step - loss: 1.3107 - acc: 0.5776 - val_loss: 1.0807 - val_acc: 0.6389\n",
      "Epoch 6/20\n",
      "322/322 [==============================] - 82s 254ms/step - loss: 1.1942 - acc: 0.6584 - val_loss: 0.9193 - val_acc: 0.6111\n",
      "Epoch 7/20\n",
      "322/322 [==============================] - 82s 256ms/step - loss: 0.9739 - acc: 0.6708 - val_loss: 0.7103 - val_acc: 0.8333\n",
      "Epoch 8/20\n",
      "322/322 [==============================] - 84s 262ms/step - loss: 0.7366 - acc: 0.7702 - val_loss: 0.9547 - val_acc: 0.6111\n",
      "Epoch 9/20\n",
      "322/322 [==============================] - 81s 252ms/step - loss: 0.5206 - acc: 0.8571 - val_loss: 0.7168 - val_acc: 0.8056\n",
      "Epoch 10/20\n",
      "322/322 [==============================] - 80s 247ms/step - loss: 0.3613 - acc: 0.8913 - val_loss: 0.6181 - val_acc: 0.8333\n",
      "Epoch 11/20\n",
      "322/322 [==============================] - 80s 247ms/step - loss: 0.3664 - acc: 0.9161 - val_loss: 0.7506 - val_acc: 0.8056\n",
      "Epoch 12/20\n",
      "322/322 [==============================] - 80s 250ms/step - loss: 0.1510 - acc: 0.9596 - val_loss: 0.5915 - val_acc: 0.8056\n",
      "Epoch 13/20\n",
      "322/322 [==============================] - 85s 263ms/step - loss: 0.0938 - acc: 0.9752 - val_loss: 0.5766 - val_acc: 0.8333\n",
      "Epoch 14/20\n",
      "322/322 [==============================] - 160s 495ms/step - loss: 0.0722 - acc: 0.9783 - val_loss: 0.7189 - val_acc: 0.8056\n",
      "Epoch 15/20\n",
      "322/322 [==============================] - 158s 491ms/step - loss: 0.0578 - acc: 0.9814 - val_loss: 0.7897 - val_acc: 0.8611\n",
      "Epoch 16/20\n",
      "322/322 [==============================] - 133s 412ms/step - loss: 0.0540 - acc: 0.9876 - val_loss: 0.6633 - val_acc: 0.8056\n",
      "Epoch 17/20\n",
      "322/322 [==============================] - 81s 250ms/step - loss: 0.0472 - acc: 0.9845 - val_loss: 0.5567 - val_acc: 0.8333\n",
      "Epoch 18/20\n",
      "322/322 [==============================] - 80s 248ms/step - loss: 0.0257 - acc: 0.9969 - val_loss: 0.6954 - val_acc: 0.8333\n",
      "Epoch 19/20\n",
      "322/322 [==============================] - 80s 250ms/step - loss: 0.0321 - acc: 0.9907 - val_loss: 0.7951 - val_acc: 0.8333\n",
      "Epoch 20/20\n",
      "322/322 [==============================] - 81s 253ms/step - loss: 0.0368 - acc: 0.9938 - val_loss: 0.7119 - val_acc: 0.8056\n"
     ]
    }
   ],
   "source": [
    "mafia_train = mafia_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = mafia_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_label_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thread_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126856</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132415</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134482</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133728</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134270</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            thread_label_id\n",
       "thread_num                 \n",
       "126856                    8\n",
       "132415                    8\n",
       "134482                    0\n",
       "133728                    1\n",
       "134270                    8"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab=pd.Series(pred)\n",
    "ans = pd.concat([thread_test[\"thread_num\"],lab], axis=1, keys=['thread_num', 'thread_label_id'])\n",
    "ans=ans.set_index(\"thread_num\")\n",
    "ans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=os.path.join(module_path,\"submissions\")\n",
    "ans.to_csv(os.path.join(path,\"sol29.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
